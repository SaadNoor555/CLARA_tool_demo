{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Code for Code Explaination\n",
        ""
      ],
      "metadata": {
        "id": "zPNA4INhEmJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "\n",
        "OPENAI_API_KEY = \"OPENAI_API_KEY\"\n",
        "DEEPSEEK_API_KEY = \"DEEPSEEK_API_KEY\"\n",
        "\n",
        "GEMINI_API_KEY = \"GEMINI_API_KEY\"\n",
        "\n",
        "# API Endpoints\n",
        "OPENAI_ENDPOINT = \"https://api.openai.com/v1/chat/completions\"\n",
        "DEEPSEEK_ENDPOINT = \"https://api.deepseek.com/chat/completions\"\n",
        "GEMINI_ENDPOINT = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent\"\n",
        "\n",
        "# --- Helper Functions for LLM Interactions ---\n",
        "\n",
        "def get_openai_response(prompt_text: str, code_content: str, api_key: str) -> str:\n",
        "\n",
        "    if not api_key or api_key == \"OPENAI_API_KEY\":\n",
        "        return \"OpenAI API Key not configured. Please set OPENAI_API_KEY.\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt_text},\n",
        "        {\"role\": \"user\", \"content\": f\"Here is the code file content:\\n```\\n{code_content}\\n```\"}\n",
        "    ]\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"gpt-4o\",\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 1000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(OPENAI_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content'].strip()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to OpenAI API: {e}\"\n",
        "    except KeyError:\n",
        "        return f\"Unexpected response format from OpenAI API: {response.text}\"\n",
        "\n",
        "def get_deepseek_response(prompt_text: str, code_content: str, api_key: str) -> str:\n",
        "    \"\"\"\n",
        "    Gets a response from Deepseek's chat completions model.\n",
        "    Assumes Deepseek API is similar to OpenAI's chat completions.\n",
        "    \"\"\"\n",
        "    if not api_key or api_key == \"YOUR_DEEPSEEK_API_KEY\":\n",
        "        return \"Deepseek API Key not configured. Please set DEEPSEEK_API_KEY.\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt_text},\n",
        "        {\"role\": \"user\", \"content\": f\"Here is the code file content:\\n```\\n{code_content}\\n```\"}\n",
        "    ]\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"deepseek-chat\",\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 1000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(DEEPSEEK_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content'].strip()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to Deepseek API: {e}\"\n",
        "    except KeyError:\n",
        "        return f\"Unexpected response format from Deepseek API: {response.text}\"\n",
        "\n",
        "def get_gemini_response(prompt_text: str, code_content: str, api_key: str) -> str:\n",
        "\n",
        "    chat_history = []\n",
        "    chat_history.append({\"role\": \"user\", \"parts\": [{\"text\": prompt_text}]})\n",
        "    chat_history.append({\"role\": \"user\", \"parts\": [{\"text\": f\"Here is the code file content:\\n```\\n{code_content}\\n```\"}]})\n",
        "\n",
        "    payload = {\"contents\": chat_history}\n",
        "    api_url = f\"{GEMINI_ENDPOINT}?key={api_key}\"\n",
        "\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(api_url, headers=headers, data=json.dumps(payload))\n",
        "        response.raise_for_status()\n",
        "        result = response.json()\n",
        "\n",
        "        if result.get('candidates') and result['candidates'][0].get('content') and \\\n",
        "           result['candidates'][0]['content'].get('parts') and \\\n",
        "           result['candidates'][0]['content']['parts'][0].get('text'):\n",
        "            return result['candidates'][0]['content']['parts'][0]['text'].strip()\n",
        "        else:\n",
        "            return f\"Unexpected response format from Gemini API: {response.text}\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to Gemini API: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"An unexpected error occurred with Gemini API: {e}\"\n",
        "\n",
        "# --- Main Logic ---\n",
        "\n",
        "def main():\n",
        "    print(\"Welcome to the LLM Code Analyzer!\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    user_prompt = input(\" `Explain the code. First in 40-50 words explain what this code file does in the context of the project repository. Then, explain what this code file does(write it in 100-120 words and write 1 small line describing each method in the code.)`;\\n\")\n",
        "\n",
        "    code_file_path = input(\"Enter the path to your code file : \")\n",
        "\n",
        "    code_content = \"\"\n",
        "    try:\n",
        "        with open(code_file_path, 'r', encoding='utf-8') as f:\n",
        "            code_content = f.read()\n",
        "        print(f\"\\nSuccessfully loaded code from '{code_file_path}' (first 100 chars):\")\n",
        "        print(code_content[:100] + \"...\" if len(code_content) > 100 else code_content)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at '{code_file_path}'. Please check the path.\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file: {e}\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nGetting responses from LLMs...\\n\")\n",
        "\n",
        "    # Get response from GPT-4o\n",
        "    print(\"--- GPT-4o Response ---\")\n",
        "    gpt_response = get_openai_response(user_prompt, code_content, OPENAI_API_KEY)\n",
        "    print(gpt_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Get response from Deepseek\n",
        "    print(\"\\n--- Deepseek Response ---\")\n",
        "    deepseek_response = get_deepseek_response(user_prompt, code_content, DEEPSEEK_API_KEY)\n",
        "    print(deepseek_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Get response from Gemini\n",
        "    print(\"\\n--- Gemini Response ---\")\n",
        "    gemini_response = get_gemini_response(user_prompt, code_content, GEMINI_API_KEY)\n",
        "    print(gemini_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "humjUihv8Umv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for code refactoring\n"
      ],
      "metadata": {
        "id": "vmkm6NZ6Ezhj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1LJCqm6EO-Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "\n",
        "OPENAI_API_KEY = \"OPENAI_API_KEY\"\n",
        "DEEPSEEK_API_KEY = \"DEEPSEEK_API_KEY\"\n",
        "GEMINI_API_KEY = \"GEMINI_API_KEY\"\n",
        "\n",
        "# API Endpoints\n",
        "OPENAI_ENDPOINT = \"https://api.openai.com/v1/chat/completions\"\n",
        "DEEPSEEK_ENDPOINT = \"https://api.deepseek.com/chat/completions\"\n",
        "GEMINI_ENDPOINT = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent\"\n",
        "\n",
        "# --- Helper Functions for LLM Interactions ---\n",
        "\n",
        "def get_openai_response(prompt_text: str, code_content: str, api_key: str) -> str:\n",
        "\n",
        "    if not api_key or api_key == \"OPENAI_API_KEY\":\n",
        "        return \"OpenAI API Key not configured. Please set OPENAI_API_KEY.\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt_text},\n",
        "        {\"role\": \"user\", \"content\": f\"Here is the code file content:\\n```\\n{code_content}\\n```\"}\n",
        "    ]\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"gpt-4o\",\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 1000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(OPENAI_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content'].strip()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to OpenAI API: {e}\"\n",
        "    except KeyError:\n",
        "        return f\"Unexpected response format from OpenAI API: {response.text}\"\n",
        "\n",
        "def get_deepseek_response(prompt_text: str, code_content: str, api_key: str) -> str:\n",
        "    \"\"\"\n",
        "    Gets a response from Deepseek's chat completions model.\n",
        "    Assumes Deepseek API is similar to OpenAI's chat completions.\n",
        "    \"\"\"\n",
        "    if not api_key or api_key == \"YOUR_DEEPSEEK_API_KEY\":\n",
        "        return \"Deepseek API Key not configured. Please set DEEPSEEK_API_KEY.\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt_text},\n",
        "        {\"role\": \"user\", \"content\": f\"Here is the code file content:\\n```\\n{code_content}\\n```\"}\n",
        "    ]\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"deepseek-chat\",\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 1000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(DEEPSEEK_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content'].strip()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to Deepseek API: {e}\"\n",
        "    except KeyError:\n",
        "        return f\"Unexpected response format from Deepseek API: {response.text}\"\n",
        "\n",
        "def get_gemini_response(prompt_text: str, code_content: str, api_key: str) -> str:\n",
        "\n",
        "    chat_history = []\n",
        "    chat_history.append({\"role\": \"user\", \"parts\": [{\"text\": prompt_text}]})\n",
        "    chat_history.append({\"role\": \"user\", \"parts\": [{\"text\": f\"Here is the code file content:\\n```\\n{code_content}\\n```\"}]})\n",
        "\n",
        "    payload = {\"contents\": chat_history}\n",
        "    api_url = f\"{GEMINI_ENDPOINT}?key={api_key}\"\n",
        "\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(api_url, headers=headers, data=json.dumps(payload))\n",
        "        response.raise_for_status()\n",
        "        result = response.json()\n",
        "\n",
        "        if result.get('candidates') and result['candidates'][0].get('content') and \\\n",
        "           result['candidates'][0]['content'].get('parts') and \\\n",
        "           result['candidates'][0]['content']['parts'][0].get('text'):\n",
        "            return result['candidates'][0]['content']['parts'][0]['text'].strip()\n",
        "        else:\n",
        "            return f\"Unexpected response format from Gemini API: {response.text}\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to Gemini API: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"An unexpected error occurred with Gemini API: {e}\"\n",
        "\n",
        "# --- Main Logic ---\n",
        "\n",
        "def main():\n",
        "    print(\"Welcome to the LLM Code Analyzer!\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    user_prompt = input(\" `Refactor the following code file and provide the complete, cleaned, and refactored version as output. Include brief comments (12â€“15 words) next to each section where refactoring was performed, explaining the changes made. Do not include any additional explanations or descriptions, just give the refactored code as output`;\\n\")\n",
        "\n",
        "    code_file_path = input(\"Enter the path to your code file : \")\n",
        "\n",
        "    code_content = \"\"\n",
        "    try:\n",
        "        with open(code_file_path, 'r', encoding='utf-8') as f:\n",
        "            code_content = f.read()\n",
        "        print(f\"\\nSuccessfully loaded code from '{code_file_path}' (first 100 chars):\")\n",
        "        print(code_content[:100] + \"...\" if len(code_content) > 100 else code_content)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at '{code_file_path}'. Please check the path.\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file: {e}\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nGetting responses from LLMs...\\n\")\n",
        "\n",
        "    # Get response from GPT-4o\n",
        "    print(\"--- GPT-4o Response ---\")\n",
        "    gpt_response = get_openai_response(user_prompt, code_content, OPENAI_API_KEY)\n",
        "    print(gpt_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Get response from Deepseek\n",
        "    print(\"\\n--- Deepseek Response ---\")\n",
        "    deepseek_response = get_deepseek_response(user_prompt, code_content, DEEPSEEK_API_KEY)\n",
        "    print(deepseek_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Get response from Gemini\n",
        "    print(\"\\n--- Gemini Response ---\")\n",
        "    gemini_response = get_gemini_response(user_prompt, code_content, GEMINI_API_KEY)\n",
        "    print(gemini_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "39Jl_fUWO-iD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for Code Quality Metrics"
      ],
      "metadata": {
        "id": "w0oFqDwQE7K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "\n",
        "OPENAI_API_KEY = \"OPENAI_API_KEY\"\n",
        "DEEPSEEK_API_KEY = \"DEEPSEEK_API_KEY\"\n",
        "GEMINI_API_KEY = \"GEMINI_API_KEY\"\n",
        "\n",
        "# API Endpoints\n",
        "OPENAI_ENDPOINT = \"https://api.openai.com/v1/chat/completions\"\n",
        "DEEPSEEK_ENDPOINT = \"https://api.deepseek.com/chat/completions\"\n",
        "GEMINI_ENDPOINT = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent\"\n",
        "\n",
        "# --- Helper Functions for LLM Interactions ---\n",
        "\n",
        "def get_openai_response(prompt_text: str, code_content: str, api_key: str) -> str:\n",
        "\n",
        "    if not api_key or api_key == \"OPENAI_API_KEY\":\n",
        "        return \"OpenAI API Key not configured. Please set OPENAI_API_KEY.\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt_text},\n",
        "        {\"role\": \"user\", \"content\": f\"Here is the code file content:\\n```\\n{code_content}\\n```\"}\n",
        "    ]\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"gpt-4o\",\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 1000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(OPENAI_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content'].strip()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to OpenAI API: {e}\"\n",
        "    except KeyError:\n",
        "        return f\"Unexpected response format from OpenAI API: {response.text}\"\n",
        "\n",
        "def get_deepseek_response(prompt_text: str, code_content: str, api_key: str) -> str:\n",
        "    \"\"\"\n",
        "    Gets a response from Deepseek's chat completions model.\n",
        "    Assumes Deepseek API is similar to OpenAI's chat completions.\n",
        "    \"\"\"\n",
        "    if not api_key or api_key == \"YOUR_DEEPSEEK_API_KEY\":\n",
        "        return \"Deepseek API Key not configured. Please set DEEPSEEK_API_KEY.\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt_text},\n",
        "        {\"role\": \"user\", \"content\": f\"Here is the code file content:\\n```\\n{code_content}\\n```\"}\n",
        "    ]\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"deepseek-chat\",\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 1000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(DEEPSEEK_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content'].strip()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to Deepseek API: {e}\"\n",
        "    except KeyError:\n",
        "        return f\"Unexpected response format from Deepseek API: {response.text}\"\n",
        "\n",
        "def get_gemini_response(prompt_text: str, code_content: str, api_key: str) -> str:\n",
        "\n",
        "    chat_history = []\n",
        "    chat_history.append({\"role\": \"user\", \"parts\": [{\"text\": prompt_text}]})\n",
        "    chat_history.append({\"role\": \"user\", \"parts\": [{\"text\": f\"Here is the code file content:\\n```\\n{code_content}\\n```\"}]})\n",
        "\n",
        "    payload = {\"contents\": chat_history}\n",
        "    api_url = f\"{GEMINI_ENDPOINT}?key={api_key}\"\n",
        "\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(api_url, headers=headers, data=json.dumps(payload))\n",
        "        response.raise_for_status()\n",
        "        result = response.json()\n",
        "\n",
        "        if result.get('candidates') and result['candidates'][0].get('content') and \\\n",
        "           result['candidates'][0]['content'].get('parts') and \\\n",
        "           result['candidates'][0]['content']['parts'][0].get('text'):\n",
        "            return result['candidates'][0]['content']['parts'][0]['text'].strip()\n",
        "        else:\n",
        "            return f\"Unexpected response format from Gemini API: {response.text}\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to Gemini API: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"An unexpected error occurred with Gemini API: {e}\"\n",
        "\n",
        "# --- Main Logic ---\n",
        "\n",
        "def main():\n",
        "    print(\"Welcome to the LLM Code Analyzer!\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    user_prompt = input(\" `Calculate the cyclomatic complexity, maintainability index and vulnerability category that suit most from CVE categories for the following code. Just check out the codes and from the code try to answer . just write the numbers.In your response only give the detected values of these attributes. Don't give any explanation`;\\n\")\n",
        "\n",
        "    code_file_path = input(\"Enter the path to your code file : \")\n",
        "\n",
        "    code_content = \"\"\n",
        "    try:\n",
        "        with open(code_file_path, 'r', encoding='utf-8') as f:\n",
        "            code_content = f.read()\n",
        "        print(f\"\\nSuccessfully loaded code from '{code_file_path}' (first 100 chars):\")\n",
        "        print(code_content[:100] + \"...\" if len(code_content) > 100 else code_content)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at '{code_file_path}'. Please check the path.\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file: {e}\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nGetting responses from LLMs...\\n\")\n",
        "\n",
        "    # Get response from GPT-4o\n",
        "    print(\"--- GPT-4o Response ---\")\n",
        "    gpt_response = get_openai_response(user_prompt, code_content, OPENAI_API_KEY)\n",
        "    print(gpt_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Get response from Deepseek\n",
        "    print(\"\\n--- Deepseek Response ---\")\n",
        "    deepseek_response = get_deepseek_response(user_prompt, code_content, DEEPSEEK_API_KEY)\n",
        "    print(deepseek_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Get response from Gemini\n",
        "    print(\"\\n--- Gemini Response ---\")\n",
        "    gemini_response = get_gemini_response(user_prompt, code_content, GEMINI_API_KEY)\n",
        "    print(gemini_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "3lkxPS-OQYSe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}